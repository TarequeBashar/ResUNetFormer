{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNipqv0BIUSaVZOOBCb/s17",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aj1365/ResUNetFormer/blob/main/ResU_NetFormer_Het.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChByVI4kU4QT"
      },
      "outputs": [],
      "source": [
        "import cv2 # For CV operations\n",
        "from PIL import Image  #To create and store images\n",
        "import numpy as np\n",
        "\n",
        "#To binarize the input\n",
        "import h5py\n",
        "import os\n",
        "from patchify import patchify"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "##### Creating input & mask arrays\n",
        "\n",
        "\n",
        "images = []\n",
        "originalImages = os.listdir(\"E:/MRD/tiff/train/\")\n",
        "\n",
        "for index,image in enumerate(originalImages):\n",
        "    print(\"Image number : \" +str(index) )\n",
        "    img = Image.open(\"E:/MRD/tiff/train/\" + str(image))\n",
        "    img = img.resize((384, 384))\n",
        "    arr = np.array(img)\n",
        "    #arr = np.expand_dims(arr, -1)\n",
        "    images.append(arr)\n",
        "\n",
        "TrainX=images\n",
        "TrainX = np.array(TrainX)\n",
        "\n",
        "\n",
        "\n",
        "images = []\n",
        "originalImages = os.listdir(\"E:/MRD/tiff/train_labels/\")\n",
        "\n",
        "for index,image in enumerate(originalImages):\n",
        "    print(\"Image number : \" +str(index) )\n",
        "    img = Image.open(\"E:/MRD/tiff/train_labels/\" + str(image))\n",
        "    img = img.resize((384, 384))\n",
        "    arr = np.array(img)\n",
        "    #arr = np.expand_dims(arr, -1)\n",
        "    images.append(arr)\n",
        "\n",
        "TrainY=images\n",
        "TrainY = np.array(TrainY)\n"
      ],
      "metadata": {
        "id": "1Lx8g5r_Vfrt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images = []\n",
        "originalImages = os.listdir(\"E:/MRD/tiff/test/\")\n",
        "\n",
        "for index,image in enumerate(originalImages):\n",
        "    print(\"Image number : \" +str(index) )\n",
        "    img = Image.open(\"E:/MRD/tiff/test/\" + str(image))\n",
        "    img = img.resize((384, 384))\n",
        "    arr = np.array(img)\n",
        "    #arr = np.expand_dims(arr, -1)\n",
        "    images.append(arr)\n",
        "\n",
        "TestX=images\n",
        "TestX = np.array(TestX)\n",
        "TestX.shape\n",
        "\n",
        "images = []\n",
        "originalImages = os.listdir(\"E:/MRD/tiff/test_labels/\")\n",
        "\n",
        "for index,image in enumerate(originalImages):\n",
        "    print(\"Image number : \" +str(index) )\n",
        "    img = Image.open(\"E:/MRD/tiff/test_labels/\" + str(image))\n",
        "    img = img.resize((384, 384))\n",
        "    arr = np.array(img)\n",
        "    #arr = np.expand_dims(arr, -1)\n",
        "    images.append(arr)\n",
        "\n",
        "TestY=images\n",
        "TestY = np.array(TestY)\n"
      ],
      "metadata": {
        "id": "jYVppjM8VmjO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainX=TrainX[0:800,:,:,:]\n",
        "TrainY=TrainY[0:800,:,:]"
      ],
      "metadata": {
        "id": "SmOBHAwwV1nu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "TrainY=TrainY.reshape(TrainY.shape[0],TrainY.shape[1],TrainY.shape[1],1)\n",
        "TestY=TestY.reshape(TestY.shape[0],TestY.shape[1],TestY.shape[1],1)\n",
        "\n",
        "TrainY.shape, TestY.shape"
      ],
      "metadata": {
        "id": "yadFVdEoV1q-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##############Finalizing Dataset for Training#######\n",
        "\n",
        "with h5py.File(\"E:/Dataset_train.h5\", 'w') as hdf:\n",
        "    hdf.create_dataset('images', data=TrainX, compression='gzip', compression_opts=9)\n",
        "    hdf.create_dataset('masks', data=TrainY, compression='gzip', compression_opts=9)"
      ],
      "metadata": {
        "id": "HblewMj8V1uG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import *\n",
        "from keras.layers import *\n",
        "from keras.optimizers import *\n",
        "import keras\n",
        "import keras.callbacks\n",
        "from keras.callbacks import TensorBoard\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras import backend as keras\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from typing import Callable\n",
        "from keras_cv_attention_models.attention_layers import (\n",
        "    activation_by_name,\n",
        "    ChannelAffine,\n",
        "    conv2d_no_bias,\n",
        "    depthwise_conv2d_no_bias,\n",
        "    drop_block,\n",
        "    #MixupToken,\n",
        "    mlp_block,\n",
        "    output_block,\n",
        "    add_pre_post_process,\n",
        ")\n",
        "from keras_cv_attention_models.download_and_load import reload_model_weights\n",
        "from keras_cv_attention_models.attention_layers import (\n",
        "    ChannelAffine,\n",
        "    CompatibleExtractPatches,\n",
        "    conv2d_no_bias,\n",
        "    drop_block,\n",
        "    layer_norm,\n",
        "    mlp_block,\n",
        "    output_block,\n",
        "    add_pre_post_process,\n",
        ")\n",
        "from keras_cv_attention_models.download_and_load import reload_model_weights\n"
      ],
      "metadata": {
        "id": "fvUtATE7V1x3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Metrics to be used when evaluating the network\n",
        "from tensorflow_addons.metrics import F1Score\n",
        "\n",
        "precision = tf.keras.metrics.Precision()\n",
        "recall = tf.keras.metrics.Recall()\n",
        "f1 = F1Score(num_classes=1, name='f1', average='micro', threshold=0.4)\n",
        "sgd_optimizer = Adam()"
      ],
      "metadata": {
        "id": "bhcM9nqOWCQA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "import tensorflow_addons as tfa\n",
        "\n",
        "tfk = tf.keras\n",
        "tfkl = tfk.layers\n",
        "tfm = tf.math\n",
        "L2_WEIGHT_DECAY = 1e-4"
      ],
      "metadata": {
        "id": "M1DAhO0jWCS4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadRelativePositionalKernelBias(tf.keras.layers.Layer):\n",
        "    def __init__(self, input_height=-1, is_heads_first=False, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.input_height, self.is_heads_first = input_height, is_heads_first\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        # input (is_heads_first=False): `[batch, height * width, num_heads, ..., size * size]`\n",
        "        # input (is_heads_first=True): `[batch, num_heads, height * width, ..., size * size]`\n",
        "        blocks, num_heads = (input_shape[2], input_shape[1]) if self.is_heads_first else (input_shape[1], input_shape[2])\n",
        "        size = int(tf.math.sqrt(float(input_shape[-1])))\n",
        "        height = self.input_height if self.input_height > 0 else int(tf.math.sqrt(float(blocks)))\n",
        "        width = blocks // height\n",
        "        pos_size = 2 * size - 1\n",
        "        initializer = tf.initializers.truncated_normal(stddev=0.02)\n",
        "        self.pos_bias = self.add_weight(name=\"positional_embedding\", shape=(num_heads, pos_size * pos_size), initializer=initializer, trainable=True)\n",
        "\n",
        "        idx_hh, idx_ww = tf.range(0, size), tf.range(0, size)\n",
        "        coords = tf.reshape(tf.expand_dims(idx_hh, -1) * pos_size + idx_ww, [-1])\n",
        "        bias_hh = tf.concat([idx_hh[: size // 2], tf.repeat(idx_hh[size // 2], height - size + 1), idx_hh[size // 2 + 1 :]], axis=-1)\n",
        "        bias_ww = tf.concat([idx_ww[: size // 2], tf.repeat(idx_ww[size // 2], width - size + 1), idx_ww[size // 2 + 1 :]], axis=-1)\n",
        "        bias_hw = tf.expand_dims(bias_hh, -1) * pos_size + bias_ww\n",
        "        bias_coords = tf.expand_dims(bias_hw, -1) + coords\n",
        "        bias_coords = tf.reshape(bias_coords, [-1, size**2])[::-1]  # torch.flip(bias_coords, [0])\n",
        "\n",
        "        bias_coords_shape = [bias_coords.shape[0]] + [1] * (len(input_shape) - 4) + [bias_coords.shape[1]]\n",
        "        self.bias_coords = tf.reshape(bias_coords, bias_coords_shape)  # [height * width, 1 * n, size * size]\n",
        "        if not self.is_heads_first:\n",
        "            self.transpose_perm = [1, 0] + list(range(2, len(input_shape) - 1))  # transpose [num_heads, height * width] -> [height * width, num_heads]\n",
        "\n",
        "    def call(self, inputs):\n",
        "        if self.is_heads_first:\n",
        "            return inputs + tf.gather(self.pos_bias, self.bias_coords, axis=-1)\n",
        "        else:\n",
        "            return inputs + tf.transpose(tf.gather(self.pos_bias, self.bias_coords, axis=-1), self.transpose_perm)\n",
        "\n",
        "    def get_config(self):\n",
        "        base_config = super().get_config()\n",
        "        base_config.update({\"input_height\": self.input_height, \"is_heads_first\": self.is_heads_first})\n",
        "        return base_config\n",
        "\n",
        "\n",
        "def LWA(\n",
        "    inputs, kernel_size=7, num_heads=4, key_dim=0, out_weight=True, qkv_bias=True, out_bias=True, attn_dropout=0, output_dropout=0, name=None\n",
        "):\n",
        "    _, hh, ww, cc = inputs.shape\n",
        "    key_dim = key_dim if key_dim > 0 else cc // num_heads\n",
        "    qk_scale = 1.0 / (float(key_dim) ** 0.5)\n",
        "    out_shape = cc\n",
        "    qkv_out = num_heads * key_dim\n",
        "\n",
        "    should_pad_hh, should_pad_ww = max(0, kernel_size - hh), max(0, kernel_size - ww)\n",
        "    if should_pad_hh or should_pad_ww:\n",
        "        inputs = tf.pad(inputs, [[0, 0], [0, should_pad_hh], [0, should_pad_ww], [0, 0]])\n",
        "        _, hh, ww, cc = inputs.shape\n",
        "\n",
        "    qkv = keras.layers.Dense(qkv_out * 3, use_bias=qkv_bias, name=name and name + \"qkv\")(inputs)\n",
        "    query, key_value = tf.split(qkv, [qkv_out, qkv_out * 2], axis=-1)  # Matching weights from PyTorch\n",
        "    query = tf.expand_dims(tf.reshape(query, [-1, hh * ww, num_heads, key_dim]), -2)  # [batch, hh * ww, num_heads, 1, key_dim]\n",
        "\n",
        "    # key_value: [batch, height // kernel_size, width // kernel_size, kernel_size, kernel_size, key + value]\n",
        "    key_value = CompatibleExtractPatches(sizes=kernel_size, strides=1, padding=\"VALID\", compressed=False)(key_value)\n",
        "    padded = (kernel_size - 1) // 2\n",
        "    # torch.pad 'replicate'\n",
        "    key_value = tf.concat([tf.repeat(key_value[:, :1], padded, axis=1), key_value, tf.repeat(key_value[:, -1:], padded, axis=1)], axis=1)\n",
        "    key_value = tf.concat([tf.repeat(key_value[:, :, :1], padded, axis=2), key_value, tf.repeat(key_value[:, :, -1:], padded, axis=2)], axis=2)\n",
        "\n",
        "    key_value = tf.reshape(key_value, [-1, kernel_size * kernel_size, key_value.shape[-1]])\n",
        "    key, value = tf.split(key_value, 2, axis=-1)  # [batch * block_height * block_width, kernel_size * kernel_size, key_dim]\n",
        "    key = tf.transpose(tf.reshape(key, [-1, key.shape[1], num_heads, key_dim]), [0, 2, 3, 1])  # [batch * hh*ww, num_heads, key_dim, kernel_size * kernel_size]\n",
        "    key = tf.reshape(key, [-1, hh * ww, num_heads, key_dim, kernel_size * kernel_size])  # [batch, hh*ww, num_heads, key_dim, kernel_size * kernel_size]\n",
        "    value = tf.transpose(tf.reshape(value, [-1, value.shape[1], num_heads, key_dim]), [0, 2, 1, 3])\n",
        "    value = tf.reshape(value, [-1, hh * ww, num_heads, kernel_size * kernel_size, key_dim])  # [batch, hh*ww, num_heads, kernel_size * kernel_size, key_dim]\n",
        "    # print(f\">>>> {query.shape = }, {key.shape = }, {value.shape = }\")\n",
        "\n",
        "    # [batch, hh * ww, num_heads, 1, kernel_size * kernel_size]\n",
        "    attention_scores = keras.layers.Lambda(lambda xx: tf.matmul(xx[0], xx[1]))([query, key]) * qk_scale\n",
        "    attention_scores = MultiHeadRelativePositionalKernelBias(input_height=hh, name=name and name + \"pos\")(attention_scores)\n",
        "    attention_scores = keras.layers.Softmax(axis=-1, name=name and name + \"attention_scores\")(attention_scores)\n",
        "    attention_scores = keras.layers.Dropout(attn_dropout, name=name and name + \"attn_drop\")(attention_scores) if attn_dropout > 0 else attention_scores\n",
        "\n",
        "    # attention_output = [batch, block_height * block_width, num_heads, 1, key_dim]\n",
        "    attention_output = keras.layers.Lambda(lambda xx: tf.matmul(xx[0], xx[1]))([attention_scores, value])\n",
        "    attention_output = tf.reshape(attention_output, [-1, hh, ww, num_heads * key_dim])\n",
        "    # print(f\">>>> {attention_output.shape = }, {attention_scores.shape = }\")\n",
        "\n",
        "    if should_pad_hh or should_pad_ww:\n",
        "        attention_output = attention_output[:, : hh - should_pad_hh, : ww - should_pad_ww, :]\n",
        "\n",
        "    if out_weight:\n",
        "        # [batch, hh, ww, num_heads * key_dim] * [num_heads * key_dim, out] --> [batch, hh, ww, out]\n",
        "        attention_output = keras.layers.Dense(out_shape, use_bias=out_bias, name=name and name + \"output\")(attention_output)\n",
        "    attention_output = keras.layers.Dropout(output_dropout, name=name and name + \"out_drop\")(attention_output) if output_dropout > 0 else attention_output\n",
        "    return attention_output"
      ],
      "metadata": {
        "id": "3gj4ajVzWCV7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "################################## LIBRARIES ##################################\n",
        "\n",
        "from tensorflow.keras.layers import Conv2D, BatchNormalization, Activation, Add, Conv2DTranspose, concatenate, Lambda, UpSampling2D\n",
        "from tensorflow.keras import Model, Input\n",
        "from contextlib import redirect_stdout\n",
        "\n",
        "\n",
        "############################# CONVOLUTIONAL BLOCK #############################\n",
        "\n",
        "def  HetConv(feature_map, conv_filter, kernel_size , strides):\n",
        "\n",
        "    # Groupwise Convolution\n",
        "    x1=Conv2D(filters=conv_filter, kernel_size=(3,3), groups=3, strides=strides, padding='same')(feature_map)\n",
        "\n",
        "    # Pointwise Convolution\n",
        "    x2= Conv2D(filters=conv_filter, kernel_size=(1,1), strides=strides, padding='same')(feature_map)\n",
        "\n",
        "\n",
        "    addition = Add()([x1, x2])\n",
        "\n",
        "    return addition\n",
        "\n",
        "\n",
        "def conv_block(feature_map):\n",
        "\n",
        "    # Main Path\n",
        "    conv_1 = HetConv(feature_map, conv_filter=66, kernel_size=(3,3), strides=(1,1))\n",
        "    bn = BatchNormalization()(conv_1)\n",
        "    relu = Activation(activation='relu')(bn)\n",
        "    conv_2 = HetConv(relu,conv_filter=66, kernel_size=(3,3), strides=(1,1))\n",
        "\n",
        "    res_conn = HetConv(feature_map,conv_filter=66, kernel_size=(1,1), strides=(1,1))\n",
        "    res_conn = BatchNormalization()(res_conn)\n",
        "    addition = Add()([res_conn, conv_2])\n",
        "\n",
        "    return addition\n",
        "\n",
        "\n",
        "############################### RESIDUAL BLOCK ################################\n",
        "\n",
        "def res_block(feature_map, conv_filter, stride):\n",
        "\n",
        "    bn_1 = BatchNormalization()(feature_map)\n",
        "    relu_1 = Activation(activation='relu')(bn_1)\n",
        "    conv_1 = HetConv(relu_1, conv_filter, kernel_size=(3,3), strides=stride[0])\n",
        "\n",
        "\n",
        "\n",
        "    bn_2 = BatchNormalization()(conv_1)\n",
        "    relu_2 = Activation(activation='relu')(bn_2)\n",
        "    conv_2 = HetConv(relu_2, conv_filter, kernel_size=(3,3), strides=stride[1])\n",
        "\n",
        "\n",
        "    res_conn = HetConv(feature_map, conv_filter, kernel_size=(1,1), strides=stride[0])\n",
        "    res_conn = BatchNormalization()(res_conn)\n",
        "    addition = Add()([res_conn, conv_2])\n",
        "\n",
        "    return addition\n",
        "\n",
        "################################### ENCODER ###################################\n",
        "\n",
        "def encoder(feature_map):\n",
        "\n",
        "    # Initialize the to_decoder connection\n",
        "    to_decoder = []\n",
        "\n",
        "    # Block 1 - Convolution Block\n",
        "    path = conv_block(feature_map)\n",
        "    to_decoder.append(path)\n",
        "\n",
        "    # Block 2 - Residual Block 1\n",
        "    path = res_block(path, 126, [(2, 2), (1, 1)])\n",
        "    to_decoder.append(path)\n",
        "\n",
        "    # Block 3 - Residual Block 2\n",
        "    path = res_block(path, 252, [(2, 2), (1, 1)])\n",
        "    to_decoder.append(path)\n",
        "\n",
        "    return to_decoder\n",
        "\n",
        "################################### DECODER ###################################\n",
        "\n",
        "def decoder(feature_map, from_encoder):\n",
        "\n",
        "    # Block 1: Up-sample, Concatenation + Residual Block 1\n",
        "    main_path = UpSampling2D(size=(2,2), interpolation='bilinear')(feature_map)\n",
        "    # main_path = Conv2DTranspose(filters=256, kernel_size=(2,2), strides=(2,2), padding='same')(feature_map)\n",
        "    main_path = concatenate([main_path, from_encoder[2]], axis=3)\n",
        "    main_path = res_block(main_path, 252, [(1, 1), (1, 1)])\n",
        "\n",
        "    # Block 2: Up-sample, Concatenation + Residual Block 2\n",
        "    main_path = UpSampling2D(size=(2,2), interpolation='bilinear')(main_path)\n",
        "    # main_path = Conv2DTranspose(filters=128, kernel_size=(2,2), strides=(2,2), padding='same')(main_path)\n",
        "    main_path = concatenate([main_path, from_encoder[1]], axis=3)\n",
        "    main_path = res_block(main_path, 126, [(1, 1), (1, 1)])\n",
        "\n",
        "    # Block 3: Up-sample, Concatenation + Residual Block 3\n",
        "    main_path = UpSampling2D(size=(2,2), interpolation='bilinear')(main_path)\n",
        "    # main_path = Conv2DTranspose(filters=64, kernel_size=(2,2), strides=(2,2), padding='same')(main_path)\n",
        "    main_path = concatenate([main_path, from_encoder[0]], axis=3)\n",
        "    main_path = res_block(main_path, 66, [(1, 1), (1, 1)])\n",
        "\n",
        "    return main_path\n",
        "\n",
        "################################ RESIDUAL UNET ################################\n",
        "n=1\n",
        "attn_kernel_size=3\n",
        "num_heads=4\n",
        "attn_drop_rate=0.1\n",
        "hidden_size=256\n",
        "\n",
        "def ResLWAUNet():\n",
        "\n",
        "    # Input\n",
        "    x = Input(shape=(384, 384, 3))\n",
        "   # model_input_float = Lambda(lambda x: x / 255)(model_input)\n",
        "\n",
        "\n",
        "    # Encoder Path\n",
        "    model_encoder = encoder(x)\n",
        "    model_bottleneck = res_block(model_encoder[2], 510, [(2, 2), (1, 1)])\n",
        "    # Transformer/Encoder\n",
        "\n",
        "    y= LWA(model_bottleneck,\n",
        "                attn_kernel_size,\n",
        "                num_heads,\n",
        "                attn_dropout=attn_drop_rate,\n",
        "                name=f\"Transformer/encoderblock_{n}\")\n",
        "\n",
        "\n",
        "    # Bottleneck\n",
        "\n",
        "    # Decoder Path\n",
        "    model_decoder = decoder(y, model_encoder)\n",
        "\n",
        "    # Output\n",
        "\n",
        "    output_layer = Conv2D(filters=1, kernel_size=(1, 1), strides=(1, 1), activation='sigmoid', padding='same')(model_decoder)\n",
        "\n",
        "\n",
        "    model=Model(inputs=x, outputs=output_layer)\n",
        "    model.compile(optimizer=sgd_optimizer, loss='binary_crossentropy', metrics=['accuracy', precision, recall, f1])\n",
        "\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "PS1mN4lFWCY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=ResLWAUNet()\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "5xgFiHKmWCbf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('*'*30)\n",
        "print('Loading and preprocessing train data...')\n",
        "print('*'*30)\n",
        "file = h5py.File('E:/Dataset_train.h5', 'r')\n",
        "imgs_train = file.get('images')\n",
        "imgs_mask_train = file.get('masks')\n",
        "imgs_train = np.array(imgs_train)\n",
        "imgs_mask_train = np.array(imgs_mask_train)\n",
        "\n",
        "print(imgs_train.shape)\n",
        "print(imgs_mask_train.shape)\n",
        "\n",
        "\n",
        "imgs_train = imgs_train.astype('float32')\n",
        "\n",
        "mean = np.mean(imgs_train)  # mean for data centering\n",
        "std = np.std(imgs_train)  # std for data normalization\n",
        "\n",
        "imgs_train -= mean\n",
        "imgs_train /= std\n",
        "\n",
        "imgs_mask_train = imgs_mask_train.astype('float32')\n",
        "imgs_mask_train /= 255  # scale masks to [0, 1]\n",
        "\n",
        "print('*'*30)\n",
        "print('Creating and compiling model...')\n",
        "print('*'*30)\n",
        "model = ResLWAUNet()"
      ],
      "metadata": {
        "id": "NrpR3IwSWCen"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weight_decay = 0.0001\n",
        "learning_rate=1e-4\n",
        "\n",
        "optimizer = tfa.optimizers.AdamW(\n",
        "        learning_rate=learning_rate, weight_decay=weight_decay\n",
        "    )\n",
        "\n",
        "\n",
        "checkpoint_filepath = \"E:/MRD100/ResUNetFormer.h5\"\n",
        "\n",
        "\n",
        "\n",
        "#with tf.device('/CPU:0'):\n",
        "history = model.fit(\n",
        "        x=imgs_train,\n",
        "        y=imgs_mask_train,\n",
        "        batch_size=1,\n",
        "        epochs=20,\n",
        "        validation_split=0.1\n",
        "    )\n"
      ],
      "metadata": {
        "id": "_GWfplfAWwyW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('E:/MRD100/ResUNetFormer.h5')"
      ],
      "metadata": {
        "id": "aPRac4xBdCVt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "###### Creating Test Dataset\n",
        "testImages=TestX\n",
        "\n",
        "testImages.shape\n",
        "\n",
        "with h5py.File(\"E:/Dataset_test.h5\", 'w') as hdf:\n",
        "    hdf.create_dataset('images', data=testImages, compression='gzip', compression_opts=9)\n",
        "\n",
        "\n",
        "\n",
        "file = h5py.File('E:/Dataset_test.h5', 'r')\n",
        "imgs_test = file.get('images')\n",
        "#imgs_mask_test = file.get('masks')\n",
        "imgs_test = np.array(imgs_test)\n",
        "#imgs_mask_test = np.array(imgs_mask_test)\n",
        "imgs_test = imgs_test.astype('float32')\n",
        "imgs_test -= mean\n",
        "imgs_test /= std\n",
        "\n",
        "print('*'*30)\n",
        "print('Loading saved weights...')\n",
        "print('*'*30)\n",
        "model.load_weights('E:/MRD100/ResUNetFormer.h5')\n",
        "\n",
        "print('*'*30)\n",
        "print('Predicting masks on test data...')\n",
        "print('*'*30)\n",
        "imgs_mask_test = model.predict(imgs_test, verbose=1,batch_size=1)\n",
        "imgs_mask_test=(imgs_mask_test - np.min(imgs_mask_test))/(np.max(imgs_mask_test) - np.min(imgs_mask_test))\n",
        "imgs_mask_test = (imgs_mask_test * 255).astype(np.uint8)\n",
        "\n",
        "#imgs_mask_test = (imgs_mask_test * 255).astype(np.uint8)"
      ],
      "metadata": {
        "id": "P_eNBawtWw1R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc = model.evaluate(imgs_test, TestY, batch_size=1)"
      ],
      "metadata": {
        "id": "63zO1i3wWw4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "######################### Write the predicted images\n",
        "\n",
        "print('*' * 30)\n",
        "print('Saving predicted masks to files...')\n",
        "print('*' * 30)\n",
        "pred_dir = 'E:/PredictionsResUNetFormer'\n",
        "\n",
        "if not os.path.exists(pred_dir):\n",
        "    os.mkdir(pred_dir)\n",
        "for i, image in enumerate(imgs_mask_test):\n",
        "    #image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    image=(image - np.min(image))/(np.max(image) - np.min(image))\n",
        "    image = (image * 255).astype(np.uint8)\n",
        "\n",
        "    cv2.imwrite(os.path.join(pred_dir, str(i + 1) + '_pred.png'), image)"
      ],
      "metadata": {
        "id": "JHVD8N9NXcY1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}